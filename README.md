# NLP
Basic NLP Techniques Project
This project demonstrates the implementation of fundamental Natural Language Processing (NLP) techniques, including:

Tokenization: Breaking text into individual words or phrases.
Stemming: Reducing words to their root forms.
Lemmatization: Converting words to their base forms with proper context.
These techniques are essential for preprocessing text data in NLP tasks like sentiment analysis, text classification, and information retrieval.
